
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">

<head>

  <title>Taolin Zhang's Homepage</title>

  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="description" content="Taolin Zhang is currently a Ph.D. student at East China Normal University, advised by Prof. Xiaofeng He.">
  <meta name="keywords" content="Taolin Zhang, Âº†Ê∂õÊûó, zhangtaolin, Taolin, Zhang, Natural Language Processing, Deep Learning, ECNU">
  <meta name="author" content="Taolin Zhang" />

  <link rel="stylesheet" href="w3.css">

  <style>
  .w3-sidebar a {font-family: "Roboto", sans-serif}
  body,h1,h2,h3,h4,h5,h6,.w3-wide {font-family: "Montserrat", sans-serif;}
  </style>

  <link rel="icon" type="image/png" href="images/icons.png">
  <!--
  <script src="jquery.min.js"></script>
  <script>
  $(document).ready(function(){
    // Add smooth scrolling to all links
    $("a").on('click', function(event) {
      // Make sure this.hash has a value before overriding default behavior
      if (this.hash !== "") {
        // Prevent default anchor click behavior
        event.preventDefault();
        // Store hash
        var hash = this.hash;
        // Using jQuery's animate() method to add smooth page scroll
        // The optional number (800) specifies the number of milliseconds it takes to scroll to the specified area
        $('html, body').animate({
          scrollTop: $(hash).offset().top
        }, 800, function(){
          // Add hash (#) to URL when done scrolling (default click behavior)
          window.location.hash = hash;
        });
      } // End if
    });
  });
  </script>
  //-->

</head>


<body class="w3-content" style="max-width:1000px">

<!-- Sidebar/menu -->
<nav class="w3-sidebar w3-bar-block w3-black w3-collapse w3-top w3-right" style="z-index:3;width:150px" id="mySidebar">
  <div class="w3-container w3-display-container w3-padding-16">
    <h3><b>TAOLIN</b></h3>
  </div>
  <div class="w3-padding-64 w3-text-light-grey w3-large" style="font-weight:bold">
    <a href="#home" class="w3-bar-item w3-button">Home</a>
    <a href="#news" class="w3-bar-item w3-button">News</a>
    <a href="#work_experience" class="w3-bar-item w3-button">Work Experience</a>
    <a href="#projects" class="w3-bar-item w3-button">Projects</a>
    <a href="#talks" class="w3-bar-item w3-button">Talks</a>
    <a href="#publications" class="w3-bar-item w3-button">Research</a>
    <a href="#service" class="w3-bar-item w3-button">Services</a>
    <a href="#award" class="w3-bar-item w3-button">Awards</a>
  </div>
</nav>

<!-- Top menu on small screens -->
<header class="w3-bar w3-top w3-hide-large w3-black w3-xlarge">
  <div class="w3-bar-item w3-padding-24">TAOLIN</div>
  <a href="javascript:void(0)" class="w3-bar-item w3-button w3-padding-24 w3-right"  style="font-stretch: extra-expanded;" onclick="w3_open()"><b>‚â°</b></a>
  </div>
</header>

<!-- Overlay effect when opening sidebar on small screens -->
<div class="w3-overlay w3-hide-large" onclick="w3_close()" style="cursor:pointer" title="close side menu" id="myOverlay"></div>

<!-- !PAGE CONTENT! -->
<div class="w3-main" style="margin-left:150px">

  <!-- Push down content on small screens -->
  <div class="w3-hide-large" style="margin-top:83px"></div>

<!-- The Home Section -->
    <div class="w3-container w3-center w3-padding-32" id="home">
      <img style="width: 80%;max-width: 320px" alt="profile photo" src="images/Yunhe_new.jpg">
      <h1>Taolin Zhang</h1>
	<p class="w3-justify" style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;max-width:600px">
        <strong>Motto:</strong> Ë∑ØÊº´Êº´ÂÖ∂‰øÆËøúÂÖÆÔºåÂêæÂ∞Ü‰∏ä‰∏ãËÄåÊ±ÇÁ¥¢ (The way was long and wrapped in gloom did seem, as I urged on to seek my vanished dream.)
	</p>
        <p class="w3-justify" style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;max-width:600px">
         Hi THEREüòÑ Currently, I am an algorithm researcher in  <a href="https://s.alibaba.com/cn/aaig/"> Alibaba Artificial Intelligence Governance Laboratory (i.e., AAIG)</a>. I have obtained my Ph.D degree from <a href="http://www.sei.ecnu.edu.cn/"> East China Normal University </a> in 07/2023, supervised by <a href="https://faculty.ecnu.edu.cn/_s16/hxf/main.psp">Prof. Xiaofeng He</a> and <a href="https://chywang.github.io/">Alibaba Algorithm Expert Chengyu Wang</a>. I have broad interests in natural language processing and multimodal applications, with a focus on knowledge-enhanced neural models and their applications in information extraction and question answering. I did my bachelors at school of computer science, <a href="http://cs.sxu.edu.cn/">Shanxi University</a>, advised by <a href="http://cs.sxu.edu.cn/faculty/professor/1469/index.htm">Prof. Hongye Tan</a>.
        </p>
        <p class="w3-center">
          <a href="zhangtl0519@gmail.com">Email</a> &nbsp/&nbsp
          <a href="https://scholar.google.com/citations?user=06Ctg4UAAAAJ&hl=zh-CN">Google Scholar</a> &nbsp/&nbsp
          <a href="https://www.zhihu.com/people/zhang-tao-lin-15"> Zhi Hu </a> &nbsp/&nbsp
          <a href="https://dblp.uni-trier.de/pid/270/2482.html"> DBLP </a>
        </p>
        </tbody></table>
  </div>

<div class="w3-container w3-light-grey w3-padding-32" id="news">
   <h2>News</h2>
      <p><li> 12/2024, 1 paper have been accepted by <a href="https://aaai.org/conference/aaai/aaai-25/">AAAI 2025</a>. </li></p>
      <p><li> 9/2024, 1 paper have been accepted by <a href="https://2024.emnlp.org/">EMNLP 2024</a>. </li></p>
      <!--
      <p><li> 04/2022, 8 papers have been accepted by <a href="https://openaccess.thecvf.com/CVPR2022">CVPR 2022</a>. </li></p>
   	  <p><li> 02/2022, Our suvery paper on vision transformer has been accepted by <a href="https://arxiv.org/pdf/2012.12556">IEEE TPAMI</a>.</li></p>
      <p><li> 09/2021, 10 papers have been accepted by <a href="https://nips.cc/Conferences/2021">NeurIPS 2021</a>.</li></p>
      <p><li> 09/2021, The journal version of versatile filters has been accepted by <a href="https://ieeexplore.ieee.org/iel7/34/4359286/09543586.pdf">IEEE TPAMI</a>.</li></p>
      <p><li> 07/2021, 1 paper has been accepted by <a href="https://iccv2021.thecvf.com/home">ICCV 2021</a>.</li></p>
      <p><li> 05/2021, 1 paper has been accepted by <a href="https://icml.cc/">ICML 2021</a>.</li></p>
      <p><li> 05/2021, I have been selected as a Senior Area Chair for <a href="http://valser.org/">VALSE 2021</a>.</li></p>
      <p><li> 03/2021, I accepted the invitation to serve as an Area Chair for <a href="https://nips.cc/Conferences/2021/">NeurIPS 2021</a>.</li></p>
      <p><li> 03/2021, 9 papers have been accepted by <a href="http://cvpr2021.theRcvf.com/">CVPR 2021</a>.</li></p>
      
      <p><li> 01/2021, I will give a talk about AdderNet at <a href="https://haet2021.github.io/speakers.html">HAET ICLR 2021 workshop</a>.</li></p>
      <p><li> 12/2020, two papers have been accepted by <a href="https://aaai.org/Conferences/AAAI-21/">AAAI 2021</a>.</li></p>
      <p><li> 11/2020, I accepted the invitation to serve as an Area Chair for <a href="https://icml.cc/Conferences/2021">ICML 2021</a>.</li></p>
      <p><li> 09/2020, six papers have been accepted by <a href="https://nips.cc/Conferences/2020">NeurIPS 2020</a>.</li></p>
      <p><li> 07/2020, one paper has been accepted by <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385">IEEE TNNLS</a>.</li></p>
      <p><li> 07/2020, one paper has been accepted by <a href="https://eccv2020.eu/accepted-papers/">ECCV 2020</a>.</li></p>
      <p><li> 06/2020, two papers have been accepted by <a href="https://icml.cc/Conferences/2020/AcceptedPapersInitial">ICML 2020</a>.</li></p>
      <p><li> 07/2020, one paper has been accepted by <a href="http://2020.acmmm.org/accepted-paper-id-list.txt">ACM MM 2020</a>.</li></p>
      <p><li> 02/2020, seven papers have been accepted by <a href="http://openaccess.thecvf.com/menu.py">CVPR 2020</a>.</li></p>
      <p><li> 01/2020, one paper has been accepted by <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385">IEEE TNNLS</a>.</li></p>
      <p><li> 11/2019, three papers have been accepted by <a href="https://aaai.org/Conferences/AAAI-20/wp-content/uploads/2020/01/AAAI-20-Accepted-Paper-List.pdf">AAAI 2020</a>.</li></p>
      -->

  </div>
	
<!-- The News Section -->
 <div class="w3-container w3-padding-32" id="work_experience">
   <h2>Work Experience</h2>
      <p><li> July 2023-Current, Senior Algorithm Engineer at Alibaba Group </li></p>
      <p><li> March 2021-July 2023, Research Intern at Alibaba Group </li></p>
      <p><li> July 2020-Sept 2020, Research Intern at iFLYTEK</li></p>
      <!--
      <p><li> 04/2022, 8 papers have been accepted by <a href="https://openaccess.thecvf.com/CVPR2022">CVPR 2022</a>. </li></p>
   	  <p><li> 02/2022, Our suvery paper on vision transformer has been accepted by <a href="https://arxiv.org/pdf/2012.12556">IEEE TPAMI</a>.</li></p>
      <p><li> 09/2021, 10 papers have been accepted by <a href="https://nips.cc/Conferences/2021">NeurIPS 2021</a>.</li></p>
      <p><li> 09/2021, The journal version of versatile filters has been accepted by <a href="https://ieeexplore.ieee.org/iel7/34/4359286/09543586.pdf">IEEE TPAMI</a>.</li></p>
      <p><li> 07/2021, 1 paper has been accepted by <a href="https://iccv2021.thecvf.com/home">ICCV 2021</a>.</li></p>
      <p><li> 05/2021, 1 paper has been accepted by <a href="https://icml.cc/">ICML 2021</a>.</li></p>
      <p><li> 05/2021, I have been selected as a Senior Area Chair for <a href="http://valser.org/">VALSE 2021</a>.</li></p>
      <p><li> 03/2021, I accepted the invitation to serve as an Area Chair for <a href="https://nips.cc/Conferences/2021/">NeurIPS 2021</a>.</li></p>
      <p><li> 03/2021, 9 papers have been accepted by <a href="http://cvpr2021.theRcvf.com/">CVPR 2021</a>.</li></p>
      
      <p><li> 01/2021, I will give a talk about AdderNet at <a href="https://haet2021.github.io/speakers.html">HAET ICLR 2021 workshop</a>.</li></p>
      <p><li> 12/2020, two papers have been accepted by <a href="https://aaai.org/Conferences/AAAI-21/">AAAI 2021</a>.</li></p>
      <p><li> 11/2020, I accepted the invitation to serve as an Area Chair for <a href="https://icml.cc/Conferences/2021">ICML 2021</a>.</li></p>
      <p><li> 09/2020, six papers have been accepted by <a href="https://nips.cc/Conferences/2020">NeurIPS 2020</a>.</li></p>
      <p><li> 07/2020, one paper has been accepted by <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385">IEEE TNNLS</a>.</li></p>
      <p><li> 07/2020, one paper has been accepted by <a href="https://eccv2020.eu/accepted-papers/">ECCV 2020</a>.</li></p>
      <p><li> 06/2020, two papers have been accepted by <a href="https://icml.cc/Conferences/2020/AcceptedPapersInitial">ICML 2020</a>.</li></p>
      <p><li> 07/2020, one paper has been accepted by <a href="http://2020.acmmm.org/accepted-paper-id-list.txt">ACM MM 2020</a>.</li></p>
      <p><li> 02/2020, seven papers have been accepted by <a href="http://openaccess.thecvf.com/menu.py">CVPR 2020</a>.</li></p>
      <p><li> 01/2020, one paper has been accepted by <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385">IEEE TNNLS</a>.</li></p>
      <p><li> 11/2019, three papers have been accepted by <a href="https://aaai.org/Conferences/AAAI-20/wp-content/uploads/2020/01/AAAI-20-Accepted-Paper-List.pdf">AAAI 2020</a>.</li></p>
      -->

  </div>
	
  
<!-- The Projects Section -->
  <div class="w3-container w3-padding-32" id="projects">
    <h2>Recent Projects</h2>
    <p class="w3-justify">
	<!--
        Actually, model compression is a kind of technique for developing portable deep neural networks with lower memory and computation costs. I have done several projects in Huawei including some smartphones' applications in 2019 and 2020 (e.g. Mate 30 and Honor V30). Currently, I am leading the AdderNet project, which aims to develop a series of deep learning models using only additions (<a href="https://www.reddit.com/r/MachineLearning/comments/ekw2s1/r_addernet_do_we_really_need_multiplications_in/">Discussions on Reddit</a>).
        -->
    </p>

        <h4><li>Yufeng: the ModelZoo of Large Models </li></h4>
        <img style="width:96%;" src="images/yufeng.png">
        <p class="w3-justify">
        <a style="color: #447ec9" href="https://s.alibaba.com/cn/LargeModel/">Project Page</a>
        </p>
        <p class="w3-justify">
	<!--
        I would like to say, <span style="color:red">AdderNet is very cool!</span> The initial idea was came up in about 2017 when climbing with some friends at Beijing. By replacing all convolutional layers (except the first and the last layers), we now can obtain comparable performance on ResNet architectures. In addition, to make the story more complete, we recent release the hardware implementation and some quantization methods. The results are quite encouraging, we can reduce both <strong>the energy consumption and thecircuit areas significantly without affecting the performance</strong>. Now, we are working on more applications to reduce the costs of launching AI algorithms such as low-level vision, detection, and NLP tasks.
        -->
	Building a series of large models based on <a href="https://tongyi.aliyun.com/"> QWEN</a> in the field of content security, "Yu Feng", to solve the high difficulty and risk challenges of audio, video, graph, text, multimodal, and multilingual scenarios. 
	</p> 

	  
    </p>

        <h4><li>EasyNLP: a Comprehensive and Easy-to-use NLP Toolkit </li></h4>
        <img style="width:96%;" src="images/easynlp.png">
        <p class="w3-justify">
        <a style="color: #447ec9" href="https://github.com/alibaba/EasyNLP">Project Page</a>
        </p>
        <p class="w3-justify">
	<!--
        I would like to say, <span style="color:red">AdderNet is very cool!</span> The initial idea was came up in about 2017 when climbing with some friends at Beijing. By replacing all convolutional layers (except the first and the last layers), we now can obtain comparable performance on ResNet architectures. In addition, to make the story more complete, we recent release the hardware implementation and some quantization methods. The results are quite encouraging, we can reduce both <strong>the energy consumption and thecircuit areas significantly without affecting the performance</strong>. Now, we are working on more applications to reduce the costs of launching AI algorithms such as low-level vision, detection, and NLP tasks.
        -->
	EasyNLP is an easy-to-use NLP development and application toolkit in PyTorch, first released inside Alibaba in 2021. It is built with scalable distributed training strategies and supports a comprehensive suite of NLP algorithms for various NLP applications. EasyNLP integrates knowledge distillation and few-shot learning for landing large pre-trained models, together with various popular multi-modality pre-trained models. It provides a unified framework of model training, inference, and deployment for real-world applications. It has powered more than 10 BUs and more than 20 business scenarios within the Alibaba group. It is seamlessly integrated to Platform of AI (PAI) products, including PAI-DSW for development, PAI-DLC for cloud-native training, PAI-EAS for serving, and PAI-Designer for zero-code model training.
        </p> 
	
	<h4><li>HugNLP: A Unified and Comprehensive Library for
Natural Language Processing </li></h4>
        <img style="width:96%;" src="images/hugnlp.png">
        <p class="w3-justify">
        <a style="color: #447ec9" href="https://github.com/wjn1996/HugNLP">Project Page</a>
        </p>
        <p class="w3-justify">
	<!--
        I would like to say, <span style="color:red">AdderNet is very cool!</span> The initial idea was came up in about 2017 when climbing with some friends at Beijing. By replacing all convolutional layers (except the first and the last layers), we now can obtain comparable performance on ResNet architectures. In addition, to make the story more complete, we recent release the hardware implementation and some quantization methods. The results are quite encouraging, we can reduce both <strong>the energy consumption and thecircuit areas significantly without affecting the performance</strong>. Now, we are working on more applications to reduce the costs of launching AI algorithms such as low-level vision, detection, and NLP tasks.
        -->
	In HugNLP, we provide some popular transformer-based models as backbones, such as BERT, RoBERTa, GPT-2, etc. We also release our pre-built KP-PLM, a novel knowledge-enhanced pre-training paradigm to inject factual knowledge and can be easily used for arbitrary PLMs. Apart from basic PLMs, we also implement some task-specific models, involving sequence classification, matching, labeling, span extraction, multi-choice, and text generation. Notably, we develop standard fine-tuning (based on CLS Head and prompt-tuning models that enable PLM tuning on classification tasks. For few-shot learning settings, HugNLP provides a prototypical network in both few-shot text classification and named entity recognition (NER).
        </p> 
	
	<!--
        <h4><li>GhostNet on MindSpore: SOTA Lightweight CV Networks</li></h4>
        <img style="width:96%;" src="images/GhostNet.png"> 
        <p class="w3-justify">
        <a style="color: #447ec9" href="https://live.huawei.com/huaweiconnect/meeting/cn/5872.html">Huawei Connect (HC) 2020</a> | <a style="color: #447ec9" href="https://www.mindspore.cn/resources/hub">MindSpore Hub</a>
        </p>
        <p class="w3-justify">
        The initial verison of GhostNet was accepted by CVPR 2020, which achieved SOTA performance on ImageNet: <span style="color:red">75.7%</span> top1 acc with only <span style="color:red">226M FLOPS</span>. In the current version, we release a series computer vision models (e.g. int8 quantization, detection, and larger networks) on <strong>MindsSpore 1.0</strong> and <strong>Mate 30 Pro (Kirin 990)</strong>.
        </p> 

        <h4><li>AI on Ascend: Real-Time Video Style Transfer</li></h4>
        <img style="width:32%;" src="images/atlas200.png"> &nbsp&nbsp <img style="width:60%;" src="images/video.gif">
        <p class="w3-justify">
        <a style="color: #447ec9" href="https://www.huaweicloud.com/intl/en-us/HDC.Cloud.html">Huawei Developer Conference (HDC) 2020</a> | <a style="color: #447ec9" href="https://developer.huaweicloud.com/exhibition/Atlas_neural_style.html">Online Demo</a>
        </p>
        <p class="w3-justify">
        This project aims to develop a video style transfer system on the <strong>Huawei Atlas 200 DK AI developer Kit</strong>. The latency of the original model for processing one image is about <span style="color:red">630ms</span>. After accelerating it using our method, the lantency now is about <span style="color:red">40ms</span>. 
        </p>  
	-->
  </div>
  
  <!-- The Talks Section -->
  <!--
  <div class="w3-container w3-light-grey w3-padding-32" id="talks">
    <h2>Talks</h2>
      <p><li> 10/2021, Vision Transformer at <a href="http://valser.org/2021/#/tutorial">VALSE 2021, Hangzhou, China</a>.</li></p>
      <p><li> 05/2021, Adder Neural Network at <a href="https://haet2021.github.io/speakers.html">HAET ICLR 2021 workshop</a>. Thanks <a href="https://datawisdom.ca/">Vahid</a> for the invitation.</li></p>
      <p><li> 06/2020, "<a href="http://valser.org/webinar/slide/slides/20200603/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9-%E5%B7%A5%E4%B8%9A%E7%95%8C%E5%92%8C%E5%AD%A6%E6%9C%AF%E7%95%8C%E7%9A%84%E5%B7%AE%E5%BC%82.pdf">AI on the Edge - Discussion on the Gap Between Industry and Academia</a>" at <a  href="http://valser.org/"><strong>VALSE</strong></a> Webinar.</li></p>
      <p><li> 05/2020, "<a href="https://www.bilibili.com/video/av925692420/">Edge AI: Progress and Future Directions</a>" at <a href="https://www.qbitai.com/"> <strong>QbitAI</strong></a> using <a  href="https://www.bilibili.com/"><strong>bilibili</strong></a>.</li></p>
  </div>
  -->
 <!-- The Publications Section -->
  <div class="w3-container w3-padding-32"" id="publications">
    <h2>Research</h2>
      <p class="w3-left-align" style="line-height:200%">
        I'm interested in devleoping knowledge-enhanced neural models for natural language processing and multimodal (e.g. pre-trained models, information extraction, and question answering).
      </p>
    <h4> Conference Papers (*: equal contribution)</h4>

    <ol>
	<p>
      <li><strong>Attribution Analysis Meets Model Editing: Advancing Knowledge Correction in Vision Language Models with VisEdit</strong>
      <br>
      Qizhou Chen, <strong>Taolin Zhang</strong>, Chengyu Wang, Xiaofeng He, Dakan Wang and Tingting Liu
      <br>
      <em>AAAI</em> 2025 (<strong>Oral</strong>) | <a style="color: #447ec9" href="https://aaai.org/conference/aaai/aaai-25/">paper</a> 
      </p>
	    
	<p>
      <li><strong>Lifelong Knowledge Editing for LLMs with Retrieval-Augmented Continuous Prompt Learning</strong>
      <br>
      Qizhou Chen*, <strong>Taolin Zhang*</strong>, Xiaofeng He, Dongyang Li, Chengyu Wang, Longtao Huang and Hui Xue
      <br>
      <em>EMNLP</em> 2024 | <a style="color: #447ec9" href="https://2024.emnlp.org/">paper</a> 
      </p>
	    
	<p>
      <li><strong> R4: Reinforced Retriever-Reorder-Responder for Retrieval-Augmented Large Language Models </strong>
      <br>
      <strong>Taolin Zhang*</strong>, Dongyang Li*, Qizhou Chen, Chengyu Wang, Longtao Huang, Hui Xue, Xiaofeng He and Jun Huang
      <br>
      <em>ECAI</em> 2024  | <a style="color: #447ec9" href="https://www.ecai2024.eu/">paper</a> 
       </p>
	    
     <p>
      <li><strong> DAFNet: Dynamic Auxiliary Fusion for Sequential Model Editing in Large Language Models </strong>
      <br>
      <strong>Taolin Zhang*</strong>, Qizhou Chen*, Dongyang Li, Chengyu Wang, Xiaofeng He, Longtao Huang, Hui Xue and Jun Huang
      <br>
      <em>ACL findings</em> 2024  | <a style="color: #447ec9" href="https://2024.aclweb.org/">paper</a> 
       </p>

      <p>
      <li><strong> On the Role of Long-tail Knowledge in Retrieval Augmented Large Language Models </strong>
      <br>
       Dongyang Li*, Junbing Yan*, <strong>Taolin Zhang*</strong>, Chengyu Wang, Xiaofeng He, Longtao Huang, Hui Xue and Jun Huang
      <br>
      <em>ACL</em> 2024  | <a style="color: #447ec9" href="https://2024.aclweb.org/">paper</a> 
       </p>
	    
      <p>
      <li><strong>KEHRL: Learning Knowledge-Enhanced Language Representations with Hierarchical Reinforcement Learning </strong>
      <br>
      Dongyang Li*, <strong>Taolin Zhang*</strong>, Longtao Huang, Chengyu Wang, XIAOFENG HE and Hui Xue
      <br>
      <em>COLING</em> 2024 | <a style="color: #447ec9" href="https://lrec-coling-2024.org/">paper</a> 
       </p>


	    <p>
      <li><strong>UniPSDA: Unsupervised Pseudo Semantic Data Augmentation for Zero-Shot Cross-LDingual Natural Language Understanding </strong>
      <br>
      Dongyang Li*, <strong>Taolin Zhang*</strong>, Jiali Deng, Longtao Huang, Chengyu Wang, XIAOFENG HE and Hui Xue
      <br>
      <em>COLING</em> 2024 | <a style="color: #447ec9" href="https://lrec-coling-2024.org/">paper</a> 
      </p>


	    <p>
      <li><strong>TRELM: Towards Robust and Efficient Pre-training for Knowledge-Enhanced Language Models </strong>
      <br>
      Junbing Yan, Chengyu Wang, <strong>Taolin Zhang</strong>, XIAOFENG HE, jun huang, Wei Zhang, Longtao Huang and hui xue
      <br>
      <em>COLING</em> 2024 | <a style="color: #447ec9" href="https://lrec-coling-2024.org/">paper</a> 
      </p>
	    
     
      <p>
      <li><strong>CIDR: A Cooperative Integrated Dynamic Refining Method for Minimal Feature Removal Problem </strong>
      <br>
      Qian Chen, <strong>Taolin Zhang</strong>, Dongyang Li, Xiaofeng He
      <br>
      <em>AAAI</em> 2024 | <a style="color: #447ec9" href="https://aaai.org/aaai-conference/">paper</a> 
      </p>
	    
      <p>
      <li><strong>Learning Knowledge-Enhanced Contextual Language Representations for Domain Natural Language Understanding</strong>
      <br>
      <strong>Taolin Zhang</strong>, Ruyao Xu, Chengyu Wang, Zhongjie Duan, Cen Chen, Minghui Qiu, Dawei Cheng, Xiaofeng He, Weining Qian
      <br>
      <em>EMNLP</em> 2023 | <a style="color: #447ec9" href="https://2023.emnlp.org/">paper</a> 
      </p>

      <p>
      <li><strong>From Complex to Simple: Unraveling the Cognitive Tree for Reasoning with Small Language Models</strong>
      <br>
	 Yan Junbing, Chengyu Wang, <strong>Taolin Zhang</strong>, Xiaofeng He, Jun Huang, Wei Zhang
      <br>
      <em>EMNLP</em> 2023 | <a style="color: #447ec9" href="https://2023.emnlp.org/">paper</a> 
      </p>

      <p>
      <li><strong>OnMKD: An Online Mutual Knowledge Distillation Framework for Passage Retrieval </strong>
      <br>
	 Jiali Deng, Dongyang Li, <strong>Taolin Zhang</strong>, Xiaofeng He
      <br>
      <em>NLPCC</em> 2023 | <a style="color: #447ec9" href="http://tcci.ccf.org.cn/conference/2023/index.php">paper</a> 
      </p>
	    
      <p>
      <li><strong>Knowledge-Enhanced Prototypical Network with Structural Semantics for Few-Shot Relation Classification</strong>
      <br>
      Yanghu Li, <strong>Taolin Zhang</strong>, Dongyang Li, Xiaofeng He
      <br>
      <em>PAKDD</em> 2023 (<strong>Oral</strong>) | <a style="color: #447ec9" href="https://pakdd2023.org/">paper</a> 
      </p>
												 
      <p>
      <li><strong>Revisiting and Advancing Chinese Natural Language Understanding with Accelerated Heterogeneous Knowledge Pre-training </strong>
      <br>
      <strong>Taolin Zhang</strong>, Junwei Dong, Jianing Wang, Chengyu Wang, Ang Wang, Yinghui Liu, Jun Huang, Yong Li, Xiaofeng He
      <br>
      <em>EMNLP</em> 2022 | <a style="color: #447ec9" href="https://arxiv.org/pdf/2210.05287.pdf">paper</a> 
      </p>
												 
      <p>
      <li><strong>EasyNLP: A Comprehensive and Easy-to-use Toolkit for Natural Language Processing </strong>
      <br>
      Chengyu Wang, Minghui Qiu, <strong>Taolin Zhang</strong>, Tingting Liu, Lei Li, Jianing Wang, Ming Wang, Jun Huang, Wei Lin
      <br>
      <em>EMNLP</em> 2022 | <a style="color: #447ec9" href="https://arxiv.org/pdf/2205.00258.pdf">paper</a> 
      </p>
      
      <p>
      <li><strong> HiCLRE: A Hierarchical Contrastive Learning Framework for Distantly Supervised Relation Extraction </strong>
      <br>
      Li Dongyang*, <strong>Taolin Zhang*</strong>, Nan Hu, Chengyu Wang, Xiaofeng He
      <br>
      <em>ACL findings</em> 2022 | <a style="color: #447ec9" href="https://arxiv.org/pdf/2205.00258.pdf">paper</a> 
      </p>
      
      <p>
      <li><strong> DKPLM: Decomposable Knowledge-enhanced Pre-trained Language Model for Natural Language Understanding </strong>
      <br>
      <strong>Taolin Zhang</strong>, Chengyu Wang, Nan Hu, Minghui Qiu, Chengguang Tang, Xiaofeng He, Jun Huang
      <br>
      <em>AAAI</em> 2022 | <a style="color: #447ec9" href="https://arxiv.org/pdf/2112.01047.pdf">paper</a> 
      </p>

      <p>
      <li><strong> HfGCN: Hierarchical fused GCN for Joint Entity and Relation Extraction </strong>
      <br>
      Wei Nong, <strong>Taolin Zhang</strong>, Shuangji Yang, Nan Hu, Xiaofeng He
      <br>
      <em>ICBK</em> 2021 | <a style="color: #447ec9" href="https://arxiv.org/pdf/2205.00258.pdf">paper</a> 
      </p>
      
      <p>
      <li><strong> HORNET: Enriching Pre-trained Language Representations with Heterogeneous Knowledge Sources </strong>
      <br>
      <strong>Taolin Zhang</strong>, Zerui Cai, Chengyu Wang, Peng Li, Yang Li, Minghui Qiu, Chengguang Tang, Xiaofeng He, Jun Huang
      <br>
      <em>CIKM</em> 2021 | <a style="color: #447ec9" href="https://dl.acm.org/doi/abs/10.1145/3459637.3482436">paper</a> 
      </p>
      
      <p>
      <li><strong> HAIN: Hierarchical Aggregation and Inference Network for Document-Level Relation Extraction </strong>
      <br>
      Nan Hu, <strong>Taolin Zhang</strong>, Shuangji Yang, Wei Nong, Xiaofeng He
      <br>
      <em>NLPCC</em> 2021 | <a style="color: #447ec9" href="https://link.springer.com/chapter/10.1007/978-3-030-88480-2_26">paper</a> 
      </p>
      
      <p>
      <li><strong>EMBERT: A Pre-trained Language Model for Chinese Medical Text Mining </strong>
      <br>
      Zerui Cai, <strong>Taolin Zhang</strong>, Chengyu Wang, Xiaofeng He
      <br>
      <em>APWEB</em> 2021 | <a style="color: #447ec9" href="https://link.springer.com/chapter/10.1007/978-3-030-85896-4_20">paper</a> 
      </p>
      
      <p>
      <li><strong>SaGCN: Structure-Aware Graph Convolution Network for Document-Level Relation Extraction </strong>
      <br>
      Shuangji Yang, <strong>Taolin Zhang</strong>, Danning Su, Nan Hu, Wei Nong, Xiaofeng He
      <br>
      <em>PAKDD</em> 2021 | <a style="color: #447ec9" href="https://link.springer.com/chapter/10.1007/978-3-030-75768-7_30">paper</a> 
      </p>
														
      <p>
      <li><strong>SMedBERT: A Knowledge-Enhanced Pre-trained Language Model with Structured Semantics for Medical Text Mining</strong>
      <br>
      <strong>Taolin Zhang</strong>, Zerui Cai, Chengyu Wang, Minghui Qiu, Bite Yang, Xiaofeng He
      <br>
      <em>ACL</em> 2021 | <a style="color: #447ec9" href="https://arxiv.org/pdf/2108.08983.pdf">paper</a> 
      </p>
											   
      <p>
      <li><strong>Knowledge-Empowered Representation Learning for Chinese Medical Reading Comprehension: Task, Model and Resources</strong>
      <br>
      <strong>Taolin Zhang</strong>, Chengyu Wang, Minghui Qiu, Bite Yang, Xiaofeng He, Jun Huang
      <br>
      <em>ACL findings</em> 2021 | <a style="color: #447ec9" href="https://arxiv.org/pdf/2008.10327.pdf">paper</a> 
      </p>

    </ol>

      <h4> Journal Papers:</h4>

      <ol>

      </ol>

    </p>
  </div>

<!-- The Services Section -->
  <div class="w3-container w3-padding-32" id="service">
    <h2>Services</h2>
      <p><li> Program Committee (PC) Members: CIKM2020, CIKM2021, AAAI2021, ICDM2022, AAAI2023, AAAI2024, ECAI2024, ICLR2025, ACL Rolling Review (for ACL, EMNLP, NAACL).</p>
      <p><li> Area Chair: EMNLP2023, ARR2024  </p>
  </div>

  <!-- The Awards Section -->
  <div class="w3-container w3-padding-32" id="award">
    <h2>Awards</h2>
    <p><li> 2022, National Scholarship</p>
    <p><li> 2022, The 8th place in the Chinese Language Understanding Evaluation Benchmark (CLUE) Contest. (8/2000+)</p>
    <p><li> 2021, Alibaba Outstanding Research Intern</p>
    <p><li> 2021, The 1st place in the Knowledge Probing of Pre-trained Language Model Contest. (1/256)</p>
    <p><li> 2021, The 1st place in the FewCLUE Contest</p>
    <p><li> 2018, Shanxi Unversity Outstanding Graduate</p>
  </div>  

  <div class="w3-light-grey w3-center w3-padding-24">

    Welcome to use this website's <a href="https://github.com/YunheWang/HomePage">source code</a>, just add a link back to here. <a href="https://www.wangyunhe.site/">&#10025;</a></br>

  <!-- Default Statcounter code for Taolin Zhang's Homepage
  https://www.wangyunhe.site -->
  No.
  <script type="text/javascript">
  var sc_project=12347113; 
  var sc_invisible=0; 
  var sc_security="21aca5d1"; 
  var sc_https=1; 
  var scJsHost = "https://";
  document.write("<sc"+"ript type='text/javascript' src='" + scJsHost+
  "statcounter.com/counter/counter.js'></"+"script>");
  </script> Visitor Since Feb 2022. Powered by <a href="https://www.w3schools.com/w3css/default.asp" title="W3.CSS" target="_blank" class="w3-hover-opacity">w3.css</a>
  <noscript>
    <div class="statcounter"><a title="Web Analytics Made Easy -
  StatCounter" href="https://statcounter.com/" target="_blank"><img
  class="statcounter" src="https://c.statcounter.com/12347113/0/21aca5d1/0/"
  alt="Web Analytics Made Easy - StatCounter"></a></div>
  </noscript>
  <!-- End of Statcounter Code -->

  </div>

  <!-- End page content -->
</div>

<script>
// Accordion 
function myAccFunc() {
  var x = document.getElementById("demoAcc");
  if (x.className.indexOf("w3-show") == -1) {
    x.className += " w3-show";
  } else {
    x.className = x.className.replace(" w3-show", "");
  }
}

// Click on the "Jeans" link on page load to open the accordion for demo purposes
document.getElementById("myBtn").click();


// Open and close sidebar
function w3_open() {
  document.getElementById("mySidebar").style.display = "block";
  document.getElementById("myOverlay").style.display = "block";
}
 
function w3_close() {
  document.getElementById("mySidebar").style.display = "none";
  document.getElementById("myOverlay").style.display = "none";
}
</script>

</body>
</html>
